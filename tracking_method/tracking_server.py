import cv2
import numpy as np
import asyncio
import json
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from aiortc import (
    RTCPeerConnection, MediaStreamTrack, RTCSessionDescription,
    RTCDataChannel
)
from av import VideoFrame
from ultralytics import YOLO
import queue
import threading
from tracking_method.processing import ocr_with_row_clustering, duplicate_text

# === NEW: supervision (ByteTrack + Annotators) ===
import supervision as sv

app = FastAPI()
pcs = set()
model = YOLO("./yolov8n.pt")  # íƒì§€ ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class YoloTrack(MediaStreamTrack):
    kind = "video"

    def __init__(self, track, data_channel=None, loop=None):
        super().__init__()
        self.track = track
        self.data_channel = data_channel
        self.loop = loop or asyncio.get_event_loop()
        self.frame_queue = queue.Queue(maxsize=1)
        self.result_frame = None
        self.lock = threading.Lock()
        self.running = True

        # === NEW: ByteTrack & Annotators ===
        self.tracker = sv.ByteTrack()  
        self.box_annotator = sv.BoxAnnotator(thickness=2) # ê²½ê³„ ìƒì ì„ ì˜ ë‘ê»˜.
        self.label_annotator = sv.LabelAnnotator(text_thickness=2, text_scale=0.5) #í…ìŠ¤íŠ¸ ë‘ê»˜.

        self.thread = threading.Thread(target=self._yolo_thread, daemon=True)
        self.thread.start()

    def _send_datachannel_safe(self, message: str):
        if self.data_channel and self.data_channel.readyState == "open":
            self.loop.call_soon_threadsafe(self.data_channel.send, message)

    def _yolo_thread(self):
        while self.running:
            try:
                frame = self.frame_queue.get(timeout=1)
                img = frame.to_ndarray(format="bgr24")
                # YOLO ì…ë ¥ í¬ê¸° í†µì¼ (ì„ íƒ)
                img = cv2.resize(img, (640, 640))

                # 1) íƒì§€
                results = model(img, verbose=False)[0]

                # 2) íƒì§€ â†’ Detections ë³€í™˜
                detections = sv.Detections.from_ultralytics(results)
                # (í•„ìš” ì‹œ ê°ë„ ì¡°ì •) conf í•„í„° ì˜ˆ: detections = detections[detections.confidence > 0.25]

                # 3) íŠ¸ë˜í‚¹ ì—…ë°ì´íŠ¸ (ByteTrack)
                #   supervision 0.19+ ë²„ì „ì€ ì¸ì ì—†ì´ë„ ë™ì‘.
                #   íŠ¹ì • í•´ìƒë„/í”„ë ˆì„ ì†ë„ ê¸°ë°˜ íŠœë‹ì´ í•„ìš”í•˜ë©´ ByteTrackArgsë¡œ ì„¸ë¶€ì„¤ì • ê°€ëŠ¥.
                tracked = self.tracker.update_with_detections(detections)

                # 4) ì‹œê°í™” (ID ë¼ë²¨)
                #   tracked.xyxy: (N,4), tracked.class_id, tracked.tracker_id ë“± ì‚¬ìš© ê°€ëŠ¥
                #   ë¼ë²¨ ë¬¸ìì—´ êµ¬ì„±
                labels = []
                for i in range(len(tracked)):
                    cls_id = int(tracked.class_id[i]) if tracked.class_id is not None else -1
                    tid = int(tracked.tracker_id[i]) if tracked.tracker_id is not None else -1
                    conf = float(tracked.confidence[i]) if tracked.confidence is not None else 0.0
                    labels.append(f"id:{tid} cls:{cls_id} conf:{conf:.2f}")

                # ë°•ìŠ¤/ë¼ë²¨ ê·¸ë¦¬ê¸°
                img_drawn = self.box_annotator.annotate(
                    scene=img.copy(),
                    detections=tracked
                )
                img_drawn = self.label_annotator.annotate(
                    scene=img_drawn,
                    detections=tracked,
                    labels=labels
                )

                # 5)  OCRì— íŠ¸ë˜í‚¹ ì •ë³´ ë°˜ì˜
              
                try:
                    # ì˜ˆì‹œ: íŠ¸ë˜í‚¹ ê²°ê³¼ë¥¼ ê°„ë‹¨ JSONìœ¼ë¡œ ì „ì†¡
                    # payload = []
                    # for i in range(len(tracked)):
                    #     x1, y1, x2, y2 = map(float, tracked.xyxy[i])
                    #     tid = int(tracked.tracker_id[i]) if tracked.tracker_id is not None else -1
                    #     cls_id = int(tracked.class_id[i]) if tracked.class_id is not None else -1
                    #     conf = float(tracked.confidence[i]) if tracked.confidence is not None else 0.0
                    #     payload.append({"id": tid, "cls": cls_id, "conf": conf, "bbox": [x1, y1, x2, y2]})
                    re =  ocr_with_row_clustering(img,detections)
                    dup =  duplicate_text(re)  
                    
                    for i in dup:
                       cv2.rectangle(img_drawn, (i[4],i[5]),(i[6],i[7]), color=(0,0,255), thickness =2)
                    #    cv2.putText(img_drawn, "diff_book", (i[4], i[5]-10), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 0.6, color = (255, 255, 255), thickness =3)
                     
                                   
                    if re is not None or len(re) != 0:
                        t = []
                        for row in re:
                            t.append({
                                "row": int(row[0]),             # í–‰ ë²ˆí˜¸
                                "text": str(row[1]),             # í…ìŠ¤íŠ¸
                                "id": int(row[2]),               # ì¸ë±ìŠ¤
                                "bbox": [float(row[3]), float(row[4]), float(row[5]), float(row[6])] }) # ë°”ìš´ë”©ë°•ìŠ¤                        
                        self._send_datachannel_safe(json.dumps({"results": t}))
                        
                        
                        
                except Exception as e:
                    print("DataChannel send error:", e)

                # 6) ê²°ê³¼ í”„ë ˆì„ êµì²´
                new_frame = VideoFrame.from_ndarray(img_drawn, format="bgr24")
                new_frame.pts = frame.pts
                new_frame.time_base = frame.time_base
                with self.lock:
                    self.result_frame = new_frame

            except queue.Empty:
                continue

    async def recv(self):
        frame = await self.track.recv()

        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except queue.Empty:
                break

        try:
            self.frame_queue.put_nowait(frame)
        except queue.Full:
            pass

        with self.lock:
            return self.result_frame if self.result_frame else frame

@app.post("/offer")
async def offer(request: Request):
    params = await request.json()
    description = RTCSessionDescription(sdp=params["sdp"], type=params["type"])
    pc = RTCPeerConnection()
    pcs.add(pc)

    loop = asyncio.get_event_loop()
    data_channel_holder = {"ch": None}
    yolo_track_holder = {"track": None}

    @pc.on("datachannel")
    def on_datachannel(channel: RTCDataChannel):
        print("ğŸ“¨ server got datachannel:", channel.label, channel.protocol)
        data_channel_holder["ch"] = channel
        # YOLO íŠ¸ë™ì´ ì´ë¯¸ ë§Œë“¤ì–´ì¡Œë‹¤ë©´ ì—°ê²°
        if yolo_track_holder["track"] is not None:
            yolo_track_holder["track"].data_channel = channel  
    
        @channel.on("close")
        def on_close():
            print(f"DataChannel closed: {channel.label}")        
                    
            
    @pc.on("track")
    def on_track(track):
        if track.kind == "video":
            yolo_track = YoloTrack(track, data_channel=data_channel_holder["ch"], loop=loop)
            yolo_track_holder["track"] = yolo_track
            pc.addTrack(yolo_track)
            
    
    @pc.on("connectionstatechange")
    async def on_connectionstatechange():
        if pc.connectionState in ["failed", "closed"]:
            await pc.close()
            pcs.discard(pc)

    await pc.setRemoteDescription(description)
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)

    return {"sdp": pc.localDescription.sdp, "type": pc.localDescription.type}