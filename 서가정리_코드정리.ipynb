{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44711ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 3 Labels, 210.8ms\n",
      "Speed: 2.2ms preprocess, 210.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(r\"E:\\다운로드\\runs\\detect\\train\\weights\\best.pt\")  # YOLO 모델 경로\n",
    "\n",
    "\n",
    "img = cv2.imread(r\"C:\\Users\\user\\Documents\\카카오톡 받은 파일\\KakaoTalk_20250310_094742100_01.jpg\",cv2.IMREAD_COLOR) \n",
    "\n",
    "results = model([img])\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    # result.show()  # display to screen\n",
    "    # result.save(filename=\"result.jpg\")  # saveto disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2261f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "def get_object_detection_boxes(results):\n",
    "    X = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes  # box 객체\n",
    "\n",
    "        if boxes is None or boxes.xyxy is None:\n",
    "            continue\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            xyxy = boxes.xyxy[i].cpu().numpy()\n",
    "            x1, y1, x2, y2 = xyxy\n",
    "            X.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "\n",
    "    return np.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a6edab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "\n",
    "def extract_text_by_boxes_easyocr(image, boxes, reader=None):\n",
    "    if reader is None:\n",
    "        reader = easyocr.Reader(['ko'])\n",
    "\n",
    "    texts = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "        if cropped.size == 0:\n",
    "            texts.append(None)\n",
    "            continue\n",
    "\n",
    "        result = reader.readtext(cropped, detail=0, paragraph=False)\n",
    "\n",
    "        if not result:\n",
    "            texts.append(None)\n",
    "        else:\n",
    "            texts.append(result[0].strip())\n",
    "            \n",
    "            \n",
    "        # print(result)    \n",
    "    return np.array(texts).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf474b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cluster_boxes(boxes, eps=800, min_samples=1):\n",
    "    \"\"\"\n",
    "    boxes: List of bounding boxes [x1, y1, x2, y2]\n",
    "    ocr_texts: OCR 결과 텍스트 리스트\n",
    "    eps: DBSCAN의 거리 임계값 (같은 행으로 간주할 y축 거리)\n",
    "    min_samples: 최소 샘플 수 (1로 하면 모든 점 포함 가능)\n",
    "    \n",
    "    return: 각 행에 대한 결과 \n",
    "    \"\"\"\n",
    "    # 박스 중심 y좌표 계산\n",
    "    y_centers = np.array([box[3] for box in boxes]).reshape(-1, 1)\n",
    "    # print(y_centers)\n",
    "    # DBSCAN으로 y축 클러스터링 → 같은 y좌표 = 같은 행\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples).fit(y_centers)\n",
    "    labels = clustering.labels_  # 각 박스가 속한 행 번호\n",
    "\n",
    "    return labels.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_ocr_clustering(image, results):\n",
    "    boxes = get_object_detection_boxes(results)\n",
    "    texts = extract_text_by_boxes_easyocr(image, boxes)\n",
    "    row_labels = cluster_boxes(boxes)\n",
    "\n",
    "    combined = np.concatenate([row_labels.reshape(-1, 1), texts.reshape(-1, 1), boxes ], axis=1)\n",
    "    return combined  # shape: (n, 1[text], 4[bbox], 1[row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e16890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '306 .' '1335' '549' '1439' '785']\n",
      " ['0' '306.953' '421' '521' '556' '764']\n",
      " ['0' '306.95' '211' '516' '311' '673']]\n"
     ]
    }
   ],
   "source": [
    "# n = 2\n",
    "# y = clustering(X,n)\n",
    "\n",
    "\n",
    "r = row_ocr_clustering(img,results)\n",
    "\n",
    "print(r)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computervision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
